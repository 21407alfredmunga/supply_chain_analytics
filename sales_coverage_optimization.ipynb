{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from pulp import LpMaximize, LpProblem, LpStatus, LpVariable, lpSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1dfcb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from Excel files\n",
    "initial_inventory = pd.read_csv('data/Prosacco-Initial-Inventory.csv')\n",
    "order_report = pd.read_csv('data/Prosacco-order-report.csv')\n",
    "production_plan = pd.read_excel('data/Prosacco-production-plan.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfff4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Inventory:\n",
      "           Category     SKU Warehouse  Available\n",
      "0    Fresh Packaged  FP2020      Kern       4063\n",
      "1    Fresh Packaged  FP3055      Kern       2032\n",
      "2  Healthy Beverage  HB0156      Kern        148\n",
      "3  Healthy Beverage  HB1016      Kern       4974\n",
      "4           Healthy  HT1045      Kern        121\n",
      "Order Report:\n",
      "         Country           City  PO/ORDER#        Categories     SKU  QTY ORD  \\\n",
      "0  United States  NEW YORK CITY     102981    Fresh Packaged  FP2020       52   \n",
      "1  United States  NEW YORK CITY     102980    Organic Beauty  OY2545       52   \n",
      "2  United States    Los Angeles     102979    Organic Beauty  OY2545        3   \n",
      "3  United States    Los Angeles     102978  Healthy Beverage  HB1016        3   \n",
      "4  United States    Los Angeles     102977           Healthy  HT1064       90   \n",
      "\n",
      "  CHANNEL WAREHOUSE Pick-Up / Delivery   Customer  SALES $  EXPECTED  \n",
      "0  Retail      Kern           Delivery  Customer1     6500     45236  \n",
      "1  Retail      Kern           Delivery  Customer1     6500     45274  \n",
      "2  Retail      Kern           Delivery  Customer1      375     45272  \n",
      "3  Retail      Kern           Delivery  Customer1      375     45206  \n",
      "4  Retail      Kern           Delivery  Customer1    11250     45213  \n",
      "Production Plan:\n",
      "   Production Plan Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
      "0              NaN        NaN         NaN         NaN         NaN         NaN   \n",
      "1              NaN        SKU        39.0        40.0        41.0        42.0   \n",
      "2              NaN     FP2020         0.0         0.0         0.0      1000.0   \n",
      "3              NaN     FP3055         0.0      1000.0         0.0      1000.0   \n",
      "4              NaN     HB0156         0.0      1000.0         0.0         0.0   \n",
      "\n",
      "   Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  Unnamed: 11  \\\n",
      "0         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "1        43.0        44.0        45.0        46.0         47.0         48.0   \n",
      "2      3000.0      5000.0      2000.0      1000.0       3000.0       1000.0   \n",
      "3         0.0      2000.0      1000.0      1000.0       1000.0          0.0   \n",
      "4         0.0         0.0         0.0         0.0          0.0          0.0   \n",
      "\n",
      "   Unnamed: 12  Unnamed: 13  Unnamed: 14 Unnamed: 15  \n",
      "0          NaN          NaN          NaN         NaN  \n",
      "1         49.0         50.0         51.0         NaN  \n",
      "2       1000.0       2000.0       2000.0       Delay  \n",
      "3       1000.0       2000.0       1000.0         NaN  \n",
      "4          0.0          0.0          0.0         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Display the heads of each dataframe\n",
    "print('Initial Inventory:')\n",
    "print(initial_inventory.head())\n",
    "\n",
    "print('Order Report:')\n",
    "print(order_report.head())\n",
    "\n",
    "print('Production Plan:')\n",
    "print(production_plan.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ca48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Inventory Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Category   12 non-null     object\n",
      " 1   SKU        12 non-null     object\n",
      " 2   Warehouse  12 non-null     object\n",
      " 3   Available  12 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 512.0+ bytes\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "Category     0\n",
      "SKU          0\n",
      "Warehouse    0\n",
      "Available    0\n",
      "dtype: int64\n",
      "\n",
      "Order Report Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2880 entries, 0 to 2879\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Country             2880 non-null   object\n",
      " 1   City                2880 non-null   object\n",
      " 2   PO/ORDER#           2880 non-null   int64 \n",
      " 3   Categories          2880 non-null   object\n",
      " 4   SKU                 2880 non-null   object\n",
      " 5   QTY ORD             2880 non-null   int64 \n",
      " 6   CHANNEL             2880 non-null   object\n",
      " 7   WAREHOUSE           2880 non-null   object\n",
      " 8   Pick-Up / Delivery  2880 non-null   object\n",
      " 9   Customer            2880 non-null   object\n",
      " 10  SALES $             2880 non-null   int64 \n",
      " 11  EXPECTED            2880 non-null   int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 270.1+ KB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "Country               0\n",
      "City                  0\n",
      "PO/ORDER#             0\n",
      "Categories            0\n",
      "SKU                   0\n",
      "QTY ORD               0\n",
      "CHANNEL               0\n",
      "WAREHOUSE             0\n",
      "Pick-Up / Delivery    0\n",
      "Customer              0\n",
      "SALES $               0\n",
      "EXPECTED              0\n",
      "dtype: int64\n",
      "\n",
      "Production Plan Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Production Plan  0 non-null      float64\n",
      " 1   Unnamed: 1       13 non-null     object \n",
      " 2   Unnamed: 2       13 non-null     float64\n",
      " 3   Unnamed: 3       13 non-null     float64\n",
      " 4   Unnamed: 4       13 non-null     float64\n",
      " 5   Unnamed: 5       13 non-null     float64\n",
      " 6   Unnamed: 6       13 non-null     float64\n",
      " 7   Unnamed: 7       13 non-null     float64\n",
      " 8   Unnamed: 8       13 non-null     float64\n",
      " 9   Unnamed: 9       13 non-null     float64\n",
      " 10  Unnamed: 10      13 non-null     float64\n",
      " 11  Unnamed: 11      13 non-null     float64\n",
      " 12  Unnamed: 12      13 non-null     float64\n",
      " 13  Unnamed: 13      13 non-null     float64\n",
      " 14  Unnamed: 14      13 non-null     float64\n",
      " 15  Unnamed: 15      1 non-null      object \n",
      "dtypes: float64(14), object(2)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "Production Plan    14\n",
      "Unnamed: 1          1\n",
      "Unnamed: 2          1\n",
      "Unnamed: 3          1\n",
      "Unnamed: 4          1\n",
      "Unnamed: 5          1\n",
      "Unnamed: 6          1\n",
      "Unnamed: 7          1\n",
      "Unnamed: 8          1\n",
      "Unnamed: 9          1\n",
      "Unnamed: 10         1\n",
      "Unnamed: 11         1\n",
      "Unnamed: 12         1\n",
      "Unnamed: 13         1\n",
      "Unnamed: 14         1\n",
      "Unnamed: 15        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display info and missing values for each dataframe\n",
    "\n",
    "print('Initial Inventory Info:')\n",
    "print(initial_inventory.info())\n",
    "print('\\nMissing values:')\n",
    "print(initial_inventory.isnull().sum())\n",
    "\n",
    "print('\\nOrder Report Info:')\n",
    "print(order_report.info())\n",
    "print('\\nMissing values:')\n",
    "print(order_report.isnull().sum())\n",
    "\n",
    "print('\\nProduction Plan Info:')\n",
    "print(production_plan.info())\n",
    "print('\\nMissing values:')\n",
    "print(production_plan.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29a502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Inventory after cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Category   12 non-null     object\n",
      " 1   SKU        12 non-null     object\n",
      " 2   Warehouse  12 non-null     object\n",
      " 3   Available  12 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 512.0+ bytes\n",
      "None\n",
      "\n",
      "Order Report after cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2880 entries, 0 to 2879\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Country             2880 non-null   object\n",
      " 1   City                2880 non-null   object\n",
      " 2   PO/ORDER#           2880 non-null   int64 \n",
      " 3   Categories          2880 non-null   object\n",
      " 4   SKU                 2880 non-null   object\n",
      " 5   QTY ORD             2880 non-null   int64 \n",
      " 6   CHANNEL             2880 non-null   object\n",
      " 7   WAREHOUSE           2880 non-null   object\n",
      " 8   Pick-Up / Delivery  2880 non-null   object\n",
      " 9   Customer            2880 non-null   object\n",
      " 10  SALES $             2880 non-null   int64 \n",
      " 11  EXPECTED            2880 non-null   int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 270.1+ KB\n",
      "None\n",
      "\n",
      "Production Plan after cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Production Plan  0 non-null      float64\n",
      " 1   Unnamed: 1       0 non-null      object \n",
      " 2   Unnamed: 2       0 non-null      float64\n",
      " 3   Unnamed: 3       0 non-null      float64\n",
      " 4   Unnamed: 4       0 non-null      float64\n",
      " 5   Unnamed: 5       0 non-null      float64\n",
      " 6   Unnamed: 6       0 non-null      float64\n",
      " 7   Unnamed: 7       0 non-null      float64\n",
      " 8   Unnamed: 8       0 non-null      float64\n",
      " 9   Unnamed: 9       0 non-null      float64\n",
      " 10  Unnamed: 10      0 non-null      float64\n",
      " 11  Unnamed: 11      0 non-null      float64\n",
      " 12  Unnamed: 12      0 non-null      float64\n",
      " 13  Unnamed: 13      0 non-null      float64\n",
      " 14  Unnamed: 14      0 non-null      float64\n",
      " 15  Unnamed: 15      0 non-null      object \n",
      "dtypes: float64(14), object(2)\n",
      "memory usage: 124.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Clean the data: drop rows with missing values and reset index for all dataframes\n",
    "initial_inventory_clean = initial_inventory.dropna().reset_index(drop=True)\n",
    "order_report_clean = order_report.dropna().reset_index(drop=True)\n",
    "production_plan_clean = production_plan.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Initial Inventory after cleaning:')\n",
    "print(initial_inventory_clean.info())\n",
    "print('\\nOrder Report after cleaning:')\n",
    "print(order_report_clean.info())\n",
    "print('\\nProduction Plan after cleaning:')\n",
    "print(production_plan_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48f67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SKUs and Inventory Counts:\n",
      "       SKU  Available\n",
      "0   FP2020       4063\n",
      "1   FP3055       2032\n",
      "2   HB0156        148\n",
      "3   HB1016       4974\n",
      "4   HT1045        121\n",
      "5   HT1064        138\n",
      "6   HT2054        187\n",
      "7   OB1265        130\n",
      "8   OF1060         32\n",
      "9   OF2035        185\n",
      "10  OP8025       2073\n",
      "11  OY2545       4250\n",
      "\n",
      "SKUs with Zero or Low Inventory (<=10 units):\n",
      "Empty DataFrame\n",
      "Columns: [SKU, Available]\n",
      "Index: []\n",
      "\n",
      "SKU with Highest Inventory: HB1016 (4974 units)\n",
      "\n",
      "FP2020 Inventory Status: 4063 units\n"
     ]
    }
   ],
   "source": [
    "# Inventory Analysis\n",
    "\n",
    "# List all SKUs and their inventory counts\n",
    "print('All SKUs and Inventory Counts:')\n",
    "print(initial_inventory_clean[['SKU', 'Available']])\n",
    "\n",
    "# Identify SKUs with zero or low inventory (threshold: 10 units)\n",
    "low_inventory = initial_inventory_clean[initial_inventory_clean['Available'] <= 10]\n",
    "print('\\nSKUs with Zero or Low Inventory (<=10 units):')\n",
    "print(low_inventory[['SKU', 'Available']])\n",
    "\n",
    "# Find the SKU with the highest inventory\n",
    "max_inventory_row = initial_inventory_clean.loc[initial_inventory_clean['Available'].idxmax()]\n",
    "print(f\"\\nSKU with Highest Inventory: {max_inventory_row['SKU']} ({max_inventory_row['Available']} units)\")\n",
    "\n",
    "# Focus on key SKU FP2020\n",
    "fp2020_row = initial_inventory_clean[initial_inventory_clean['SKU'] == 'FP2020']\n",
    "if not fp2020_row.empty:\n",
    "    print(f\"\\nFP2020 Inventory Status: {fp2020_row.iloc[0]['Available']} units\")\n",
    "else:\n",
    "    print('\\nFP2020 not found in inventory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b4e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Orders by SKU:\n",
      "       SKU  Order Count\n",
      "0   FP2020          625\n",
      "1   FP3055          253\n",
      "2   HB0156           52\n",
      "3   HB1016          747\n",
      "4   HT1045           46\n",
      "5   HT1064           13\n",
      "6   HT2054           13\n",
      "7   OB1265           47\n",
      "8   OF1060           10\n",
      "9   OF2035           56\n",
      "10  OP8025          346\n",
      "11  OY2545          672\n",
      "\n",
      "Top 3 SKUs by Order Volume:\n",
      "       SKU  Order Count\n",
      "3   HB1016          747\n",
      "11  OY2545          672\n",
      "0   FP2020          625\n",
      "\n",
      "Bottom 3 SKUs by Order Volume:\n",
      "      SKU  Order Count\n",
      "8  OF1060           10\n",
      "6  HT2054           13\n",
      "5  HT1064           13\n",
      "\n",
      "Order Volume vs Inventory Level:\n",
      "       SKU  Order Count  Available\n",
      "0   FP2020          625       4063\n",
      "1   FP3055          253       2032\n",
      "2   HB0156           52        148\n",
      "3   HB1016          747       4974\n",
      "4   HT1045           46        121\n",
      "5   HT1064           13        138\n",
      "6   HT2054           13        187\n",
      "7   OB1265           47        130\n",
      "8   OF1060           10         32\n",
      "9   OF2035           56        185\n",
      "10  OP8025          346       2073\n",
      "11  OY2545          672       4250\n"
     ]
    }
   ],
   "source": [
    "# Order Analysis\n",
    "\n",
    "# Summarize total orders by SKU\n",
    "orders_by_sku = order_report_clean.groupby('SKU').size().reset_index(name='Order Count')\n",
    "print('Total Orders by SKU:')\n",
    "print(orders_by_sku)\n",
    "\n",
    "# Identify SKUs with high order volumes (top 3)\n",
    "top_orders = orders_by_sku.sort_values('Order Count', ascending=False).head(3)\n",
    "print('\\nTop 3 SKUs by Order Volume:')\n",
    "print(top_orders)\n",
    "\n",
    "# Identify SKUs with low order volumes (bottom 3)\n",
    "low_orders = orders_by_sku.sort_values('Order Count', ascending=True).head(3)\n",
    "print('\\nBottom 3 SKUs by Order Volume:')\n",
    "print(low_orders)\n",
    "\n",
    "# Compare order volumes to inventory levels\n",
    "comparison = pd.merge(orders_by_sku, initial_inventory_clean[['SKU', 'Available']], on='SKU', how='left')\n",
    "print('\\nOrder Volume vs Inventory Level:')\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69b2e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required columns (Week, SKU, Produced) not found in production_plan_clean.\n"
     ]
    }
   ],
   "source": [
    "# Production Plan Analysis\n",
    "# Visualize production levels by SKU and week\n",
    "if 'Week' in production_plan_clean.columns and 'SKU' in production_plan_clean.columns and 'Produced' in production_plan_clean.columns:\n",
    "    pivot = production_plan_clean.pivot_table(index='Week', columns='SKU', values='Produced', aggfunc='sum')\n",
    "    pivot.plot(figsize=(12,6))\n",
    "    plt.title('Production Levels by SKU and Week')\n",
    "    plt.ylabel('Produced Units')\n",
    "    plt.xlabel('Week')\n",
    "    plt.legend(title='SKU')\n",
    "    plt.show()\n",
    "\n",
    "    # Identify weeks with zero production for any SKU\n",
    "    zero_prod = production_plan_clean[production_plan_clean['Produced'] == 0]\n",
    "    print('\\nWeeks with Zero Production for Any SKU:')\n",
    "    print(zero_prod[['Week', 'SKU']])\n",
    "\n",
    "    # Highlight delays or gaps in production for FP2020\n",
    "    fp2020_zero = production_plan_clean[(production_plan_clean['SKU'] == 'FP2020') & (production_plan_clean['Produced'] == 0)]\n",
    "    print('\\nFP2020 Zero Production Weeks:')\n",
    "    print(fp2020_zero['Week'].unique())\n",
    "else:\n",
    "    print('Required columns (Week, SKU, Produced) not found in production_plan_clean.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b8dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Plan Clean Columns:\n",
      "Index(['Production Plan', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3',\n",
      "       'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',\n",
      "       'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12',\n",
      "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display column names to identify correct columns for production analysis\n",
    "print('Production Plan Clean Columns:')\n",
    "print(production_plan_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f43d286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Production Plan, Unnamed: 1, Unnamed: 2, Unnamed: 3, Unnamed: 4, Unnamed: 5, Unnamed: 6, Unnamed: 7, Unnamed: 8, Unnamed: 9, Unnamed: 10, Unnamed: 11, Unnamed: 12, Unnamed: 13, Unnamed: 14, Unnamed: 15]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the structure of production_plan_clean\n",
    "print(production_plan_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbccc9b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SKU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SKU'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Re-import the production plan data without dropping missing values and inspect the first few rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m production_plan_matrix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Prosacco-production-plan.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m production_plan_matrix \u001b[38;5;241m=\u001b[39m production_plan_matrix[\u001b[43mproduction_plan_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[1;32m      4\u001b[0m production_plan_long \u001b[38;5;241m=\u001b[39m production_plan_matrix\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m], var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(production_plan_long\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SKU'"
     ]
    }
   ],
   "source": [
    "# Re-import the production plan data without dropping missing values and inspect the first few rows\n",
    "production_plan_matrix = pd.read_excel('data/Prosacco-production-plan.xlsx', header=1)\n",
    "production_plan_matrix = production_plan_matrix[production_plan_matrix['SKU'].notnull()]\n",
    "production_plan_long = production_plan_matrix.melt(id_vars=['SKU'], var_name='Week', value_name='Produced')\n",
    "print(production_plan_long.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "472ffc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15']\n"
     ]
    }
   ],
   "source": [
    "# Check column names after reading the Excel file\n",
    "production_plan_matrix = pd.read_excel('data/Prosacco-production-plan.xlsx', header=1)\n",
    "print('Columns:', production_plan_matrix.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fe2d5c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SKU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SKU'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m production_plan_matrix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Prosacco-production-plan.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Remove any rows where SKU is NaN or not a string\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m production_plan_matrix \u001b[38;5;241m=\u001b[39m production_plan_matrix[\u001b[43mproduction_plan_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Melt the dataframe to long format: SKU, Week, Produced\u001b[39;00m\n\u001b[1;32m     10\u001b[0m production_plan_long \u001b[38;5;241m=\u001b[39m production_plan_matrix\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m], var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/supply_chain_analytics/datascience_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SKU'"
     ]
    }
   ],
   "source": [
    "# Clean and reshape the production plan data for analysis\n",
    "\n",
    "# Use the second row as header (row index 1) and skip the first row\n",
    "production_plan_matrix = pd.read_excel('data/Prosacco-production-plan.xlsx', header=1)\n",
    "\n",
    "# Remove any rows where SKU is NaN or not a string\n",
    "production_plan_matrix = production_plan_matrix[production_plan_matrix['SKU'].notnull()]\n",
    "\n",
    "# Melt the dataframe to long format: SKU, Week, Produced\n",
    "production_plan_long = production_plan_matrix.melt(id_vars=['SKU'], var_name='Week', value_name='Produced')\n",
    "\n",
    "# Display the first few rows of the reshaped data\n",
    "print(production_plan_long.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adcde6a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'production_plan_long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pivot for visualization: Weeks as index, SKUs as columns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m pivot \u001b[38;5;241m=\u001b[39m \u001b[43mproduction_plan_long\u001b[49m\u001b[38;5;241m.\u001b[39mpivot_table(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduced\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m pivot\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduction Levels by SKU and Week\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'production_plan_long' is not defined"
     ]
    }
   ],
   "source": [
    "# Production Plan Analysis: Visualize and detect gaps/delays\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pivot for visualization: Weeks as index, SKUs as columns\n",
    "pivot = production_plan_long.pivot_table(index='Week', columns='SKU', values='Produced', aggfunc='sum')\n",
    "pivot.plot(figsize=(12,6))\n",
    "plt.title('Production Levels by SKU and Week')\n",
    "plt.ylabel('Produced Units')\n",
    "plt.xlabel('Week')\n",
    "plt.legend(title='SKU')\n",
    "plt.show()\n",
    "\n",
    "# Identify weeks with zero production for any SKU\n",
    "zero_prod = production_plan_long[production_plan_long['Produced'] == 0]\n",
    "print('\\nWeeks with Zero Production for Any SKU:')\n",
    "print(zero_prod[['Week', 'SKU']])\n",
    "\n",
    "# Highlight delays or gaps in production for FP2020\n",
    "fp2020_zero = production_plan_long[(production_plan_long['SKU'] == 'FP2020') & (production_plan_long['Produced'] == 0)]\n",
    "print('\\nFP2020 Zero Production Weeks:')\n",
    "print(fp2020_zero['Week'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1123dd",
   "metadata": {},
   "source": [
    "## 6. Linear programming: optimised allocation\n",
    "We now construct a linear program that reallocates Prosacco supply across cities to maximise fulfilled demand. The model treats each SKU separately, combining on-hand inventory with the forward production plan to determine weekly supply. Decision variables capture the quantity shipped from the warehouse to each market, constrained by supply availability and customer demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare aggregated demand and supply for optimisation\n",
    "demand_by_city_sku = (\n",
    "    order_report_clean.groupby([\"City\", \"SKU\"])[\"QTY ORD\"].sum().reset_index(name=\"Demand\")\n",
    ")\n",
    "demand_by_city_sku = demand_by_city_sku[demand_by_city_sku[\"Demand\"] > 0]\n",
    "\n",
    "inventory_supply = initial_inventory_clean.groupby(\"SKU\")[\"Available\"].sum().rename(\"Inventory\")\n",
    "production_supply = production_plan_long.groupby(\"SKU\")[\"Produced\"].sum().rename(\"Production\") if \"Produced\" in production_plan_long.columns else pd.Series(dtype=float)\n",
    "\n",
    "supply_by_sku = pd.concat([inventory_supply, production_supply], axis=1).fillna(0)\n",
    "supply_by_sku[\"TotalSupply\"] = supply_by_sku.sum(axis=1)\n",
    "\n",
    "skus = sorted(set(demand_by_city_sku[\"SKU\"]) | set(supply_by_sku.index))\n",
    "cities = sorted(demand_by_city_sku[\"City\"].unique())\n",
    "\n",
    "print(\"SKUs considered:\", skus)\n",
    "print(\"Cities considered:\", cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transportation lane configuration (costs & capacities)\n",
    "lane_config = pd.read_csv(\"data/Prosacco-lane-costs.csv\")\n",
    "lane_config[\"City\"] = lane_config[\"City\"].str.strip()\n",
    "lane_config.set_index(\"City\", inplace=True)\n",
    "\n",
    "lane_capacity = lane_config[\"MaxCapacity\"]\n",
    "lane_cost = lane_config[\"CostPerUnit\"]\n",
    "lane_cost_lookup = lane_cost.to_dict()\n",
    "lane_capacity_lookup = lane_capacity.to_dict()\n",
    "avg_cost = lane_cost.mean()\n",
    "missing_cities = sorted(set(cities) - set(lane_config.index))\n",
    "if missing_cities:\n",
    "    print(\"Warning: missing lane data for\", missing_cities)\n",
    "else:\n",
    "    print(\"All cities covered in lane configuration.\")\n",
    "\n",
    "cost_weight = 0.0015  # penalty weight translating cost into service-equivalent units\n",
    "print(f\"Average lane cost: {avg_cost:.2f} | Cost weight: {cost_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09979ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulate and solve the linear program with cost & capacity considerations\n",
    "shipments = {\n",
    "    (row[\"SKU\"], row[\"City\"]): LpVariable(\n",
    "        f\"ship_{row['SKU']}_{row['City'].replace(' ', '_')}\", lowBound=0\n",
    "    )\n",
    "    for _, row in demand_by_city_sku.iterrows()\n",
    "}\n",
    "\n",
    "cost_per_lane = {\n",
    "    (row[\"SKU\"], row[\"City\"]): lane_cost_lookup.get(row[\"City\"], avg_cost)\n",
    "    for _, row in demand_by_city_sku.iterrows()\n",
    "}\n",
    "\n",
    "model = LpProblem(\"Prosacco_Service_vs_Cost\", LpMaximize)\n",
    "service_expr = lpSum(var for var in shipments.values())\n",
    "cost_expr = lpSum(cost_per_lane[key] * var for key, var in shipments.items())\n",
    "model += service_expr - cost_weight * cost_expr, \"Maximise_Service_Minimise_Cost\"\n",
    "\n",
    "for sku in skus:\n",
    "    available = float(supply_by_sku.loc[sku, \"TotalSupply\"]) if sku in supply_by_sku.index else 0.0\n",
    "    relevant_vars = [var for (s, _), var in shipments.items() if s == sku]\n",
    "    if relevant_vars:\n",
    "        model += lpSum(relevant_vars) <= available, f\"supply_{sku}\"\n",
    "\n",
    "for city in cities:\n",
    "    cap = lane_capacity_lookup.get(city)\n",
    "    lane_vars = [var for (sku, c), var in shipments.items() if c == city]\n",
    "    if lane_vars and cap is not None:\n",
    "        model += lpSum(lane_vars) <= cap, f\"lane_capacity_{city.replace(' ', '_')}\"\n",
    "\n",
    "for (sku, city), var in shipments.items():\n",
    "    demand = float(demand_by_city_sku.loc[(demand_by_city_sku[\"SKU\"] == sku) & (demand_by_city_sku[\"City\"] == city), \"Demand\"].sum())\n",
    "    model += var <= demand, f\"demand_{sku}_{city}\"\n",
    "\n",
    "status = model.solve()\n",
    "total_service = service_expr.value()\n",
    "total_cost = cost_expr.value()\n",
    "print(\"Solver status:\", LpStatus[status])\n",
    "print(\"Objective value (service - weighted cost):\", model.objective.value())\n",
    "print(f\"Fulfilled units: {total_service:.0f} | Estimated transport cost: ${total_cost:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise the optimisation outcome\n",
    "allocation_df = pd.DataFrame([\n",
    "    {\"SKU\": sku, \"City\": city, \"Allocated\": var.value() or 0.0}\n",
    "    for (sku, city), var in shipments.items()\n",
    "])\n",
    "allocation_df[\"CostPerUnit\"] = allocation_df[\"City\"].map(lane_cost_lookup).fillna(avg_cost)\n",
    "allocation_df[\"TransportCost\"] = allocation_df[\"Allocated\"] * allocation_df[\"CostPerUnit\"]\n",
    "\n",
    "sku_demand = demand_by_city_sku.groupby(\"SKU\")[\"Demand\"].sum()\n",
    "sku_fulfilled = allocation_df.groupby(\"SKU\")[\"Allocated\"].sum()\n",
    "sku_results = pd.concat([sku_demand, sku_fulfilled], axis=1).fillna(0)\n",
    "sku_results.columns = [\"Demand\", \"Allocated\"]\n",
    "sku_results[\"FillRate\"] = sku_results[\"Allocated\"] / sku_results[\"Demand\"].replace({0: np.nan})\n",
    "sku_results[\"RemainingSupply\"] = supply_by_sku[\"TotalSupply\"].reindex(sku_results.index).fillna(0) - sku_results[\"Allocated\"]\n",
    "sku_results[\"TransportCost\"] = allocation_df.groupby(\"SKU\")[\"TransportCost\"].sum().reindex(sku_results.index).fillna(0)\n",
    "sku_results[\"Shortage\"] = sku_results[\"Demand\"] - sku_results[\"Allocated\"]\n",
    "print(\"SKU-level summary:\")\n",
    "display(sku_results.round(2))\n",
    "\n",
    "city_fulfilled = allocation_df.groupby(\"City\")[\"Allocated\"].sum()\n",
    "city_demand = demand_by_city_sku.groupby(\"City\")[\"Demand\"].sum()\n",
    "city_cost = allocation_df.groupby(\"City\")[\"TransportCost\"].sum()\n",
    "city_results = pd.concat([city_demand, city_fulfilled, city_cost], axis=1).fillna(0)\n",
    "city_results.columns = [\"Demand\", \"Allocated\", \"TransportCost\"]\n",
    "city_results[\"FillRate\"] = city_results[\"Allocated\"] / city_results[\"Demand\"].replace({0: np.nan})\n",
    "\n",
    "lane_capacity_used = allocation_df.groupby(\"City\")[\"Allocated\"].sum().reindex(lane_capacity.index).fillna(0)\n",
    "lane_summary = pd.concat(\n",
    "    [lane_capacity.rename(\"Capacity\"), lane_capacity_used.rename(\"Utilised\")], axis=1\n",
    ").fillna(0)\n",
    "lane_summary[\"UtilisationPct\"] = np.where(\n",
    "    lane_summary[\"Capacity\"] > 0,\n",
    "    (lane_summary[\"Utilised\"] / lane_summary[\"Capacity\"]) * 100,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "print(\"\\nCity-level summary:\")\n",
    "display(city_results.round(2))\n",
    "\n",
    "print(\"\\nLane capacity utilisation:\")\n",
    "display(lane_summary.round({\"Capacity\": 0, \"Utilised\": 0, \"UtilisationPct\": 1}))\n",
    "\n",
    "total_cost_reported = allocation_df[\"TransportCost\"].sum()\n",
    "print(f\"\\nTotal transport cost (from allocation): ${total_cost_reported:,.2f}\")\n",
    "print(\"\\nAllocation preview:\")\n",
    "display(allocation_df.sort_values([\"SKU\", \"City\"]).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fcf2b",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- **Objective**: maximise total units served while penalising expensive transport moves (weight = 0.0015).\n",
    "- **Fill rate lift**: compare the optimisation fill rates to the descriptive results above to identify SKUs where targeted reallocations deliver the biggest gains.\n",
    "- **Remaining supply**: positive balances indicate latent capacity that could be reassigned to future demand or held as safety stock.\n",
    "- **Transport spend**: the total cost output quantifies the trade-off between service and spend—tune the weight or lane tariffs to assess sensitivities.\n",
    "- **Lane utilisation**: utilisation percentages highlight routes that are capacity constrained and may require additional carriers or alternative fulfillment paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc3d97",
   "metadata": {},
   "source": [
    "# Analysis Plan for Sales Coverage Optimization\n",
    "\n",
    "1. **Data Overview**\n",
    "   - Display heads and info for Initial Inventory, Order Report, and Production Plan.\n",
    "   - Check for missing values and data types.\n",
    "\n",
    "2. **Inventory Analysis**\n",
    "   - List all SKUs and their inventory counts.\n",
    "   - Identify SKUs with zero or low inventory.\n",
    "   - Find the SKU with the highest inventory.\n",
    "   - Focus on key SKUs (e.g., FP2020) and their inventory status.\n",
    "\n",
    "3. **Order Analysis**\n",
    "   - Summarize total orders by SKU.\n",
    "   - Identify SKUs with high/low order volumes.\n",
    "   - Compare order volumes to inventory levels.\n",
    "\n",
    "4. **Production Plan Analysis**\n",
    "   - Visualize production levels by SKU and week.\n",
    "   - Identify weeks with zero production for any SKU.\n",
    "   - Highlight delays or gaps in production (e.g., FP2020 in weeks 39–41).\n",
    "\n",
    "5. **Supply-Demand Alignment**\n",
    "   - Compare inventory, orders, and production for each SKU.\n",
    "   - Flag SKUs at risk of stockouts or overstock.\n",
    "\n",
    "6. **Recommendations**\n",
    "   - Suggest actions for SKUs with mismatched supply and demand.\n",
    "   - Recommend production adjustments or inventory reallocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
